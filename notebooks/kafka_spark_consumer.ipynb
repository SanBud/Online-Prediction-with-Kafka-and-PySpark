{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-3.23.0-py3-none-any.whl (15.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.8 MB 470 kB/s eta 0:00:01     |████████████████████████████▏   | 13.9 MB 6.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydantic\n",
      "  Downloading pydantic-1.10.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2 MB 2.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from gradio) (5.4.1)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.9/site-packages (from gradio) (2021.5.0)\n",
      "Collecting httpx\n",
      "  Downloading httpx-0.23.3-py3-none-any.whl (71 kB)\n",
      "\u001b[K     |████████████████████████████████| 71 kB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting python-multipart\n",
      "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
      "\u001b[K     |████████████████████████████████| 45 kB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting uvicorn\n",
      "  Downloading uvicorn-0.21.1-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown-it-py[linkify]>=2.0.0\n",
      "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "\u001b[K     |████████████████████████████████| 84 kB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from gradio) (1.20.3)\n",
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.9/site-packages (from gradio) (8.2.0)\n",
      "Requirement already satisfied: markupsafe in /opt/conda/lib/python3.9/site-packages (from gradio) (2.0.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from gradio) (1.2.4)\n",
      "Collecting websockets>=10.0\n",
      "  Downloading websockets-10.4-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting altair>=4.2.0\n",
      "  Downloading altair-4.2.2-py3-none-any.whl (813 kB)\n",
      "\u001b[K     |████████████████████████████████| 813 kB 2.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting huggingface-hub\n",
      "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
      "\u001b[K     |████████████████████████████████| 199 kB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (from gradio) (3.4.2)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 2.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ffmpy\n",
      "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
      "Collecting semantic-version\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from gradio) (3.7.4.3)\n",
      "Collecting orjson\n",
      "  Downloading orjson-3.8.8-cp39-cp39-manylinux_2_28_x86_64.whl (143 kB)\n",
      "\u001b[K     |████████████████████████████████| 143 kB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fastapi\n",
      "  Downloading fastapi-0.95.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mdit-py-plugins<=0.3.3\n",
      "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiofiles\n",
      "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from gradio) (2.25.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from gradio) (3.0.1)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.9/site-packages (from altair>=4.2.0->gradio) (0.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.9/site-packages (from altair>=4.2.0->gradio) (3.2.0)\n",
      "Requirement already satisfied: toolz in /opt/conda/lib/python3.9/site-packages (from altair>=4.2.0->gradio) (0.11.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub->gradio) (20.9)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.10.3-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub->gradio) (4.61.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (49.6.0.post20210108)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.17.3)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (21.2.0)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting linkify-it-py<3,>=1\n",
      "  Downloading linkify_it_py-2.0.0-py3-none-any.whl (19 kB)\n",
      "Collecting uc-micro-py\n",
      "  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub->gradio) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas->gradio) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas->gradio) (2021.1)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
      "\u001b[K     |████████████████████████████████| 264 kB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
      "\u001b[K     |████████████████████████████████| 158 kB 2.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting charset-normalizer<4.0,>=2.0\n",
      "  Downloading charset_normalizer-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
      "\u001b[K     |████████████████████████████████| 199 kB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[K     |████████████████████████████████| 114 kB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.9/site-packages (from yarl<2.0,>=1.0->aiohttp->gradio) (2.10)\n",
      "Collecting starlette<0.27.0,>=0.26.1\n",
      "  Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n",
      "\u001b[K     |████████████████████████████████| 66 kB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing-extensions\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting anyio<5,>=3.4.0\n",
      "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
      "\u001b[K     |████████████████████████████████| 80 kB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette<0.27.0,>=0.26.1->fastapi->gradio) (1.2.0)\n",
      "Collecting rfc3986[idna2008]<2,>=1.3\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.9/site-packages (from httpx->gradio) (2021.5.30)\n",
      "Collecting httpcore<0.17.0,>=0.15.0\n",
      "  Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
      "\u001b[K     |████████████████████████████████| 69 kB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting h11<0.15,>=0.13\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib->gradio) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->gradio) (1.3.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from requests->gradio) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->gradio) (1.26.5)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.9/site-packages (from uvicorn->gradio) (7.1.2)\n",
      "Building wheels for collected packages: ffmpy\n",
      "  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4709 sha256=c440189a1908cb697b28ee12d48ccda6010701dd829cb7402c7ec4d6e4eb68e0\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/91/e2/96/f676aa08bfd789328c6576cd0f1fde4a3d686703bb0c247697\n",
      "Successfully built ffmpy\n",
      "Installing collected packages: uc-micro-py, typing-extensions, rfc3986, multidict, mdurl, h11, frozenlist, anyio, yarl, starlette, pydantic, markdown-it-py, linkify-it-py, httpcore, filelock, charset-normalizer, async-timeout, aiosignal, websockets, uvicorn, semantic-version, python-multipart, pydub, orjson, mdit-py-plugins, huggingface-hub, httpx, ffmpy, fastapi, altair, aiohttp, aiofiles, gradio\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.3\n",
      "    Uninstalling typing-extensions-3.7.4.3:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.3\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 3.1.0\n",
      "    Uninstalling anyio-3.1.0:\n",
      "      Successfully uninstalled anyio-3.1.0\n",
      "  Attempting uninstall: altair\n",
      "    Found existing installation: altair 4.1.0\n",
      "    Uninstalling altair-4.1.0:\n",
      "      Successfully uninstalled altair-4.1.0\n",
      "Successfully installed aiofiles-23.1.0 aiohttp-3.8.4 aiosignal-1.3.1 altair-4.2.2 anyio-3.6.2 async-timeout-4.0.2 charset-normalizer-3.1.0 fastapi-0.95.0 ffmpy-0.3.0 filelock-3.10.3 frozenlist-1.3.3 gradio-3.23.0 h11-0.14.0 httpcore-0.16.3 httpx-0.23.3 huggingface-hub-0.13.3 linkify-it-py-2.0.0 markdown-it-py-2.2.0 mdit-py-plugins-0.3.3 mdurl-0.1.2 multidict-6.0.4 orjson-3.8.8 pydantic-1.10.7 pydub-0.25.1 python-multipart-0.0.6 rfc3986-1.5.0 semantic-version-2.10.0 starlette-0.26.1 typing-extensions-4.5.0 uc-micro-py-1.0.1 uvicorn-0.21.1 websockets-10.4 yarl-1.8.2\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n",
      "\u001b[K     |████████████████████████████████| 469 kB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fsspec[http]>=2021.11.1\n",
      "  Downloading fsspec-2023.3.0-py3-none-any.whl (145 kB)\n",
      "\u001b[K     |████████████████████████████████| 145 kB 2.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from datasets) (5.4.1)\n",
      "Collecting tqdm>=4.62.1\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001b[K     |████████████████████████████████| 212 kB 3.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from datasets) (20.9)\n",
      "Collecting pyarrow>=6.0.0\n",
      "  Downloading pyarrow-11.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 34.9 MB 3.8 MB/s eta 0:00:01                 | 9.1 MB 3.7 MB/s eta 0:00:07��        | 26.2 MB 4.6 MB/s eta 0:00:02████████████████████████      | 28.4 MB 7.8 MB/s eta 0:00:01MB/s eta 0:00:01     |███████████████████████████▏    | 29.7 MB 7.8 MB/s eta 0:00:01��███▊    | 30.2 MB 7.8 MB/s eta 0:00:01��████    | 30.6 MB 7.8 MB/s eta 0:00:01     |███████████████████████████████▋| 34.5 MB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /opt/conda/lib/python3.9/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from datasets) (1.2.4)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from datasets) (1.20.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.9/site-packages (from datasets) (2.25.1)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from datasets) (0.3.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /opt/conda/lib/python3.9/site-packages (from datasets) (0.13.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets) (3.1.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.10.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Collecting dill<0.3.7,>=0.3.0\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "\u001b[K     |████████████████████████████████| 110 kB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: tqdm, fsspec, dill, xxhash, responses, pyarrow, multiprocess, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.61.0\n",
      "    Uninstalling tqdm-4.61.0:\n",
      "      Successfully uninstalled tqdm-4.61.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2021.5.0\n",
      "    Uninstalling fsspec-2021.5.0:\n",
      "      Successfully uninstalled fsspec-2021.5.0\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.3\n",
      "    Uninstalling dill-0.3.3:\n",
      "      Successfully uninstalled dill-0.3.3\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 4.0.0\n",
      "    Uninstalling pyarrow-4.0.0:\n",
      "      Successfully uninstalled pyarrow-4.0.0\n",
      "Successfully installed datasets-2.10.1 dill-0.3.6 fsspec-2023.3.0 multiprocess-0.70.14 pyarrow-11.0.0 responses-0.18.0 tqdm-4.65.0 xxhash-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_json\n",
    "from pyspark.sql.types import StructType, StructField, BooleanType, LongType, IntegerType,StringType\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "\n",
    "# Event data schema\n",
    "schema_pv = StructType(\n",
    "    [StructField(\"Summons Number\",LongType(),True),\n",
    "     StructField(\"Plate ID\",StringType(),True),\n",
    "     StructField(\"Registration State\",StringType(),True),\n",
    "     StructField(\"Plate Type\",StringType(),True),\n",
    "     StructField(\"Issue Date\",StringType(),True),\n",
    "     StructField(\"Violation Code\",IntegerType(),True),\n",
    "     StructField(\"Vehicle Body Type\",StringType(),True),\n",
    "     StructField(\"Vehicle Make\",StringType(),True),\n",
    "     StructField(\"Issuing Agency\",StringType(),True),\n",
    "     StructField(\"Street Code1\",IntegerType(),True),\n",
    "     StructField(\"Street Code2\",IntegerType(),True),\n",
    "     StructField(\"Street Code3\",IntegerType(),True),\n",
    "     StructField(\"Vehicle Expiration Date\",IntegerType(),True),\n",
    "     StructField(\"Violation Location\",IntegerType(),True),\n",
    "     StructField(\"Violation Precinct\",IntegerType(),True),\n",
    "     StructField(\"Issuer Precinct\",IntegerType(),True),\n",
    "     StructField(\"Issuer Code\",IntegerType(),True),\n",
    "     StructField(\"Issuer Command\",StringType(),True),\n",
    "     StructField(\"Issuer Squad\",StringType(),True),\n",
    "     StructField(\"Violation Time\",StringType(),True),\n",
    "     StructField(\"Time First Observed\",StringType(),True),\n",
    "     StructField(\"Violation County\",StringType(),True),\n",
    "     StructField(\"Violation In Front Of Or Opposite\",StringType(),True),\n",
    "     StructField(\"House Number\",StringType(),True),\n",
    "     StructField(\"Street Name\",StringType(),True),\n",
    "     StructField(\"Intersecting Street\",StringType(),True),\n",
    "     StructField(\"Date First Observed\",IntegerType(),True),\n",
    "     StructField(\"Law Section\",IntegerType(),True),\n",
    "     StructField(\"Sub Division\",StringType(),True),\n",
    "     StructField(\"Violation Legal Code\",StringType(),True),\t \n",
    "     StructField(\"Days Parking In Effect\",StringType(),True),\n",
    "     StructField(\"From Hours In Effect\",StringType(),True),\n",
    "     StructField(\"To Hours In Effect\",StringType(),True),\n",
    "     StructField(\"Vehicle Color\",StringType(),True),\n",
    "     StructField(\"Unregistered Vehicle?\",IntegerType(),True),\n",
    "     StructField(\"Vehicle Year\",StringType(),True),\n",
    "     StructField(\"Meter Number\",StringType(),True),\n",
    "     StructField(\"Feet From Curb\",IntegerType(),True),\n",
    "     StructField(\"Violation Post Code\",StringType(),True),\n",
    "     StructField(\"Violation Description\",StringType(),True),\n",
    "     StructField(\"No Standing or Stopping Violation\",StringType(),True),\n",
    "     StructField(\"Hydrant Violation\",StringType(),True),\n",
    "     StructField(\"Double Parking Violation\",StringType(),True),\n",
    "     StructField(\"Latitude\",StringType(),True),\n",
    "     StructField(\"Longitude\",StringType(),True),\n",
    "     StructField(\"Community Board\",StringType(),True),\n",
    "     StructField(\"Community Council\",StringType(),True),\n",
    "     StructField(\"Census Tract\",StringType(),True),\n",
    "     StructField(\"BIN\",StringType(),True),\n",
    "     StructField(\"BBL\",StringType(),True),\n",
    "     StructField(\"NTA\",StringType(),True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns_selected = [\"Registration State\",\"Plate Type\",\\\n",
    "                \"Violation Code\", \"Vehicle Body Type\",\"Vehicle Make\",\"Issuing Agency\", \"Street Code1\", \\\n",
    "               \"Street Code2\",\"Street Code3\",\"Violation Location\",\"Violation Precinct\", \\\n",
    "               \"Issuer Precinct\",\"Issuer Code\",\"Issuer Command\",\\\n",
    "               \"Violation County\",\"Law Section\",\"Sub Division\",\"Vehicle Color\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.feature import VectorAssembler, VectorIndexer, OneHotEncoder, StringIndexer\n",
    "import pyspark.sql.types as T\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import isnull, when, count, col, isnan\n",
    "\n",
    "def preprocess_data(df,pm):\n",
    "#     df.printSchema()\n",
    "#     df.count(), len(df.columns)\n",
    "    df = df.select(columns_selected)\n",
    "\n",
    "    # clean up the data as many have incorrect values.\n",
    "    df = df[(df['Registration State'] != \"99\") \\\n",
    "        & (df['Plate Type'] != \"999\") \\\n",
    "        & (df['Violation Code'] != 0)]\n",
    "    # clean up the data\n",
    "    # Check if the null value still exist\n",
    "#     df.select([count(when(isnull(c), c)).alias(c) for c in df.columns]).show()\n",
    "\n",
    "    df = df.na.drop()\n",
    "    df.dropDuplicates()\n",
    "\n",
    "    # convert to required type\n",
    "    cols = [F.col(field[0]).cast('double') if (field[1] == 'int') else F.col(field[0]) for field in df.dtypes]\n",
    "    df = df.select(cols)\n",
    "\n",
    "    #use model to transform\n",
    "#     pm = PipelineModel.load(\"../pretrained_models/va_model\")\n",
    "\n",
    "    df = pm.transform(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_data(df,pr_model):\n",
    "      #use ml model to predict\n",
    "#     pred_model = PipelineModel.load(\"../pretrained_models/rf_model\")\n",
    "    data = df.select(F.col(\"features_scaled\").alias(\"features\"))\n",
    "    # use the PipelineModel object to perform prediciton on  data. \n",
    "    prediction = pred_model.transform(data)\n",
    "\n",
    "    # print the results\n",
    "    # prediction.select('label','prediction','Violation_Location').show(5)\n",
    "    prediction.select('prediction','Violation_Location').show(10)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Spark session & context\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .master('local')\n",
    "         .appName('NY PV app')\n",
    "         .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.1\")         \n",
    "         .getOrCreate())\n",
    "sc = spark.sparkContext\n",
    "# print(spark)\n",
    "\n",
    "df = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"kafka-server:9092\") \\\n",
    "  .option(\"subscribe\", \"park.violation\") \\\n",
    "  .option(\"includeHeaders\", \"true\") \\\n",
    "  .option(\"startingOffsets\", \"latest\") \\\n",
    "  .load()\n",
    "\n",
    "df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")\n",
    "raw_path = \"pv-data\"\n",
    "checkpoint_path = \"pv-data-checkpoint\"\n",
    "\n",
    "# Following code is Working to save json files. \n",
    "# queryStream =(\n",
    "#     df_pv\n",
    "#     .writeStream\n",
    "#     .format(\"json\")\n",
    "#     .queryName(\"pv_data_ingestion\")\n",
    "#     .option(\"checkpointLocation\", checkpoint_path)\n",
    "#     .option(\"path\", raw_path)\n",
    "#     .outputMode(\"append\")\n",
    "#     .start())\n",
    "\n",
    "# !@@# The data is not getting converted to desired type with schema_pv. The reason coul dbe gthe data is incorect\n",
    "# Example Integer type has 8 a well as 8.0. And conversion fails. \n",
    "queryMem = df.select(from_json(col(\"value\").cast(\"string\"),schema_pv).alias(\"data\")).select(\"data.*\") \\\n",
    "    .writeStream \\\n",
    "    .format(\"memory\") \\\n",
    "    .queryName(\"ny_pv_count\") \\\n",
    "    .outputMode(\"update\") \\\n",
    "    .start()\n",
    "\n",
    "# consoleOut = df_pv \\\n",
    "#     .writeStream \\\n",
    "#     .trigger(processingTime='5 seconds') \\\n",
    "#     .format(\"console\") \\\n",
    "#     .queryName(\"ny_pv_console\") \\\n",
    "#     .outputMode(\"update\") \\\n",
    "#     .start()\n",
    "\n",
    "# consoleOut.awaitTermination()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "# from pyspark.sql.types import StringType\n",
    "\n",
    "# df = spark \\\n",
    "#   .readStream \\\n",
    "#   .format(\"kafka\") \\\n",
    "#   .option(\"kafka.bootstrap.servers\", \"kafka-server:9092\") \\\n",
    "#   .option(\"subscribe\", \"park.violation\") \\\n",
    "#   .option(\"includeHeaders\", \"true\") \\\n",
    "#   .option(\"startingOffsets\", \"latest\") \\\n",
    "#   .load()\\\n",
    "#   .select(from_json(col(\"value\").cast(\"string\"),schema_pv).alias(\"data\")).select(\"data.*\") \\\n",
    "#   .writeStream \\\n",
    "#   .format(\"memory\") \\\n",
    "#   .queryName(\"ny_pv_count\") \\\n",
    "#   .start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID:065b3353-1d8f-4a2e-9b23-4211e06c1fbc | NAME:ny_pv_count\n"
     ]
    }
   ],
   "source": [
    "# Check active streams\n",
    "for s in spark.streams.active:\n",
    "    print(\"ID:{} | NAME:{}\".format(s.id, s.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Following will consume data as kafka subscriber and later use spark MLlib to predict the streaming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading msg...\n",
      "Pre processing data\n",
      "Predicting live data..\n",
      "+----------+------------------+\n",
      "|prediction|Violation_Location|\n",
      "+----------+------------------+\n",
      "|       1.0|               1.0|\n",
      "+----------+------------------+\n",
      "\n",
      "Expected Violation Location: \n",
      "+------------------+\n",
      "|Violation Location|\n",
      "+------------------+\n",
      "|                 1|\n",
      "+------------------+\n",
      "\n",
      "Pre processing data\n",
      "Predicting live data..\n",
      "+----------+------------------+\n",
      "|prediction|Violation_Location|\n",
      "+----------+------------------+\n",
      "|       9.0|              84.0|\n",
      "+----------+------------------+\n",
      "\n",
      "Expected Violation Location: \n",
      "+------------------+\n",
      "|Violation Location|\n",
      "+------------------+\n",
      "|                71|\n",
      "+------------------+\n",
      "\n",
      "Pre processing data\n",
      "Predicting live data..\n",
      "+----------+------------------+\n",
      "|prediction|Violation_Location|\n",
      "+----------+------------------+\n",
      "|       9.0|              84.0|\n",
      "+----------+------------------+\n",
      "\n",
      "Expected Violation Location: \n",
      "+------------------+\n",
      "|Violation Location|\n",
      "+------------------+\n",
      "|                90|\n",
      "+------------------+\n",
      "\n",
      "Pre processing data\n",
      "Predicting live data..\n",
      "+----------+------------------+\n",
      "|prediction|Violation_Location|\n",
      "+----------+------------------+\n",
      "|       9.0|              84.0|\n",
      "+----------+------------------+\n",
      "\n",
      "Expected Violation Location: \n",
      "+------------------+\n",
      "|Violation Location|\n",
      "+------------------+\n",
      "|                79|\n",
      "+------------------+\n",
      "\n",
      "Pre processing data\n",
      "Predicting live data..\n",
      "+----------+------------------+\n",
      "|prediction|Violation_Location|\n",
      "+----------+------------------+\n",
      "|       9.0|              84.0|\n",
      "+----------+------------------+\n",
      "\n",
      "Expected Violation Location: \n",
      "+------------------+\n",
      "|Violation Location|\n",
      "+------------------+\n",
      "|                84|\n",
      "+------------------+\n",
      "\n",
      "Pre processing data\n",
      "Predicting live data..\n",
      "+----------+------------------+\n",
      "|prediction|Violation_Location|\n",
      "+----------+------------------+\n",
      "|       0.0|              19.0|\n",
      "+----------+------------------+\n",
      "\n",
      "Expected Violation Location: \n",
      "+------------------+\n",
      "|Violation Location|\n",
      "+------------------+\n",
      "|                 5|\n",
      "+------------------+\n",
      "\n",
      "Pre processing data\n",
      "Predicting live data..\n",
      "+----------+------------------+\n",
      "|prediction|Violation_Location|\n",
      "+----------+------------------+\n",
      "|       9.0|              84.0|\n",
      "+----------+------------------+\n",
      "\n",
      "Expected Violation Location: \n",
      "+------------------+\n",
      "|Violation Location|\n",
      "+------------------+\n",
      "|                79|\n",
      "+------------------+\n",
      "\n",
      "Pre processing data\n",
      "Predicting live data..\n",
      "+----------+------------------+\n",
      "|prediction|Violation_Location|\n",
      "+----------+------------------+\n",
      "|       3.0|              18.0|\n",
      "+----------+------------------+\n",
      "\n",
      "Expected Violation Location: \n",
      "+------------------+\n",
      "|Violation Location|\n",
      "+------------------+\n",
      "|                28|\n",
      "+------------------+\n",
      "\n",
      "Pre processing data\n",
      "Predicting live data..\n",
      "+----------+------------------+\n",
      "|prediction|Violation_Location|\n",
      "+----------+------------------+\n",
      "|       3.0|              18.0|\n",
      "+----------+------------------+\n",
      "\n",
      "Expected Violation Location: \n",
      "+------------------+\n",
      "|Violation Location|\n",
      "+------------------+\n",
      "|                26|\n",
      "+------------------+\n",
      "\n",
      "Pre processing data\n",
      "Predicting live data..\n",
      "+----------+------------------+\n",
      "|prediction|Violation_Location|\n",
      "+----------+------------------+\n",
      "+----------+------------------+\n",
      "\n",
      "Expected Violation Location: \n",
      "+------------------+\n",
      "|Violation Location|\n",
      "+------------------+\n",
      "|                14|\n",
      "+------------------+\n",
      "\n",
      "Pre processing data\n",
      "Predicting live data..\n",
      "+----------+------------------+\n",
      "|prediction|Violation_Location|\n",
      "+----------+------------------+\n",
      "+----------+------------------+\n",
      "\n",
      "Expected Violation Location: \n",
      "+------------------+\n",
      "|Violation Location|\n",
      "+------------------+\n",
      "|                66|\n",
      "+------------------+\n",
      "\n",
      "Pre processing data\n",
      "Predicting live data..\n",
      "+----------+------------------+\n",
      "|prediction|Violation_Location|\n",
      "+----------+------------------+\n",
      "|      36.0|              66.0|\n",
      "+----------+------------------+\n",
      "\n",
      "Expected Violation Location: \n",
      "+------------------+\n",
      "|Violation Location|\n",
      "+------------------+\n",
      "|                66|\n",
      "+------------------+\n",
      "\n",
      "Pre processing data\n",
      "Predicting live data..\n",
      "+----------+------------------+\n",
      "|prediction|Violation_Location|\n",
      "+----------+------------------+\n",
      "|       9.0|              84.0|\n",
      "+----------+------------------+\n",
      "\n",
      "Expected Violation Location: \n",
      "+------------------+\n",
      "|Violation Location|\n",
      "+------------------+\n",
      "|                84|\n",
      "+------------------+\n",
      "\n",
      "Pre processing data\n",
      "Predicting live data..\n",
      "+----------+------------------+\n",
      "|prediction|Violation_Location|\n",
      "+----------+------------------+\n",
      "|       0.0|              19.0|\n",
      "+----------+------------------+\n",
      "\n",
      "Expected Violation Location: \n",
      "+------------------+\n",
      "|Violation Location|\n",
      "+------------------+\n",
      "|                46|\n",
      "+------------------+\n",
      "\n",
      "Pre processing data\n",
      "Predicting live data..\n",
      "+----------+------------------+\n",
      "|prediction|Violation_Location|\n",
      "+----------+------------------+\n",
      "+----------+------------------+\n",
      "\n",
      "Expected Violation Location: \n",
      "+------------------+\n",
      "|Violation Location|\n",
      "+------------------+\n",
      "|                25|\n",
      "+------------------+\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "field Violation Location: IntegerType can not accept object nan in type <class 'float'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-174-c14626f58308>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Summons Number'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Violation Code'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Street Code1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Street Code2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Street Code3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Vehicle Expiration Date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Violation Precinct'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Violation Location'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Issuer Precinct'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Date First Observed'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Issuer Code'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Unregistered Vehicle?'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Feet From Curb'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Law Section'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Summons Number'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Violation Code'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Street Code1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Street Code2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Street Code3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Vehicle Expiration Date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Violation Precinct'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Violation Location'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Issuer Precinct'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Date First Observed'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Issuer Code'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Unregistered Vehicle?'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Feet From Curb'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Law Section'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0mspark_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema_pv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Pre processing data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mvec_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36mcreateDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_pandas\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0;31m# Create a DataFrame from pandas DataFrame.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m             return super(SparkSession, self).createDataFrame(\n\u001b[0m\u001b[1;32m    674\u001b[0m                 data, schema, samplingRatio, verifySchema)\n\u001b[1;32m    675\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverifySchema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/pandas/conversion.py\u001b[0m in \u001b[0;36mcreateDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    298\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_from_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimezone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverifySchema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_from_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimezone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_create_dataframe\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromLocal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m         \u001b[0mjrdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerDeUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoJavaArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_java_object_rdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplySchemaToPythonRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_createFromLocal\u001b[0;34m(self, data, schema)\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;31m# make sure data could consumed multiple times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                 \u001b[0mverify_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/types.py\u001b[0m in \u001b[0;36mverify\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1407\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mverify_nullability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m             \u001b[0mverify_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/types.py\u001b[0m in \u001b[0;36mverify_struct\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1388\u001b[0m                                 \"length of fields (%d)\" % (len(obj), len(verifiers))))\n\u001b[1;32m   1389\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverifier\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverifiers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m                     \u001b[0mverifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__dict__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m                 \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/types.py\u001b[0m in \u001b[0;36mverify\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1407\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mverify_nullability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m             \u001b[0mverify_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/types.py\u001b[0m in \u001b[0;36mverify_integer\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1327\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mverify_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m             \u001b[0massert_acceptable_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m             \u001b[0mverify_acceptable_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2147483648\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2147483647\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m                 raise ValueError(\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/types.py\u001b[0m in \u001b[0;36mverify_acceptable_types\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0;31m# subclass of them can not be fromInternal in JVM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_acceptable_types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m             raise TypeError(new_msg(\"%s can not accept object %r in type %s\"\n\u001b[0m\u001b[1;32m   1292\u001b[0m                                     % (dataType, obj, type(obj))))\n\u001b[1;32m   1293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: field Violation Location: IntegerType can not accept object nan in type <class 'float'>"
     ]
    }
   ],
   "source": [
    "from kafka import KafkaAdminClient, KafkaConsumer, KafkaProducer\n",
    "import sys\n",
    "import json\n",
    "from json import loads\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType\n",
    "import gradio as gr\n",
    "import joblib\n",
    "import datasets\n",
    "\n",
    "# Spark session & context\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .master('local')\n",
    "         .appName('NY PV app')\n",
    "         .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.1\")         \n",
    "         .getOrCreate())\n",
    "sc = spark.sparkContext\n",
    "\n",
    "### Setting up the Python consumer\n",
    "bootstrap_servers = ['kafka-server:9092']\n",
    "topicName = 'park.violation'\n",
    "consumer = KafkaConsumer (topicName, group_id = 'id1',bootstrap_servers = bootstrap_servers,\n",
    "    auto_offset_reset = 'earliest',value_deserializer=lambda x: loads(x.decode('utf-8')))  ## You can also set it as latest\n",
    "\n",
    "#use model to transform\n",
    "pm = PipelineModel.load(\"../pretrained_models/va_model\")\n",
    "# use pre trained model to infer\n",
    "pred_model = PipelineModel.load(\"../pretrained_models/rf_model\")\n",
    "\n",
    "### Reading the message from consumer\n",
    "# Poll for new messages from Kafka and print them.\n",
    "try:\n",
    "    while True:\n",
    "        msg = consumer.poll(5.0)\n",
    "        if msg is None:\n",
    "            print(\"Waiting...\")\n",
    "#         elif msg.error():\n",
    "#             print(\"ERROR: %s\".format(msg.error()))\n",
    "        else:\n",
    "            print(\"reading msg...\")\n",
    "            for message in consumer:\n",
    "                df = pd.json_normalize(message.value)\n",
    "                df[['Summons Number','Violation Code', 'Street Code1', 'Street Code2', 'Street Code3', 'Vehicle Expiration Date', 'Violation Precinct','Violation Location','Issuer Precinct','Date First Observed','Issuer Code','Unregistered Vehicle?','Feet From Curb','Law Section']] = \\\n",
    "                df[['Summons Number','Violation Code', 'Street Code1', 'Street Code2', 'Street Code3', 'Vehicle Expiration Date', 'Violation Precinct','Violation Location','Issuer Precinct','Date First Observed','Issuer Code','Unregistered Vehicle?','Feet From Curb','Law Section']].apply(pd.to_numeric)\n",
    "                spark_df = spark.createDataFrame(data=df,schema=schema_pv)\n",
    "                print('Pre processing data')\n",
    "                vec_df = preprocess_data(spark_df,pm)\n",
    "                print('Predicting live data..')\n",
    "                pr = predict_data(vec_df,pred_model).toPandas()\n",
    "                print('Expected Violation Location: '),spark_df.select('Violation Location').show(1)\n",
    "    pass\n",
    "finally:\n",
    "    # Leave group and commit final offsets\n",
    "    consumer.close()\n",
    "    spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:1\n",
      "root\n",
      " |-- Summons Number: string (nullable = true)\n",
      " |-- Plate ID: string (nullable = true)\n",
      " |-- Registration State: string (nullable = true)\n",
      " |-- Plate Type: string (nullable = true)\n",
      " |-- Issue Date: string (nullable = true)\n",
      " |-- Violation Code: string (nullable = true)\n",
      " |-- Vehicle Body Type: string (nullable = true)\n",
      " |-- Vehicle Make: string (nullable = true)\n",
      " |-- Issuing Agency: string (nullable = true)\n",
      " |-- Street Code1: string (nullable = true)\n",
      " |-- Street Code2: string (nullable = true)\n",
      " |-- Street Code3: string (nullable = true)\n",
      " |-- Vehicle Expiration Date: string (nullable = true)\n",
      " |-- Violation Location: string (nullable = true)\n",
      " |-- Violation Precinct: string (nullable = true)\n",
      " |-- Issuer Precinct: string (nullable = true)\n",
      " |-- Issuer Code: string (nullable = true)\n",
      " |-- Issuer Command: string (nullable = true)\n",
      " |-- Issuer Squad: string (nullable = true)\n",
      " |-- Violation Time: string (nullable = true)\n",
      " |-- Time First Observed: string (nullable = true)\n",
      " |-- Violation County: string (nullable = true)\n",
      " |-- Violation In Front Of Or Opposite: string (nullable = true)\n",
      " |-- House Number: string (nullable = true)\n",
      " |-- Street Name: string (nullable = true)\n",
      " |-- Intersecting Street: string (nullable = true)\n",
      " |-- Date First Observed: string (nullable = true)\n",
      " |-- Law Section: string (nullable = true)\n",
      " |-- Sub Division: string (nullable = true)\n",
      " |-- Violation Legal Code: string (nullable = true)\n",
      " |-- Days Parking In Effect: string (nullable = true)\n",
      " |-- From Hours In Effect: string (nullable = true)\n",
      " |-- To Hours In Effect: string (nullable = true)\n",
      " |-- Vehicle Color: string (nullable = true)\n",
      " |-- Unregistered Vehicle?: integer (nullable = true)\n",
      " |-- Vehicle Year: string (nullable = true)\n",
      " |-- Meter Number: string (nullable = true)\n",
      " |-- Feet From Curb: string (nullable = true)\n",
      " |-- Violation Post Code: string (nullable = true)\n",
      " |-- Violation Description: string (nullable = true)\n",
      " |-- No Standing or Stopping Violation: string (nullable = true)\n",
      " |-- Hydrant Violation: string (nullable = true)\n",
      " |-- Double Parking Violation: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      " |-- Community Board: string (nullable = true)\n",
      " |-- Community Council: string (nullable = true)\n",
      " |-- Census Tract: string (nullable = true)\n",
      " |-- BIN: string (nullable = true)\n",
      " |-- BBL: string (nullable = true)\n",
      " |-- NTA: string (nullable = true)\n",
      "\n",
      "+--------------+--------+------------------+----------+----------+--------------+-----------------+------------+--------------+------------+------------+------------+-----------------------+------------------+------------------+---------------+-----------+--------------+------------+--------------+-------------------+----------------+---------------------------------+------------+-------------------+-------------------+-------------------+-----------+------------+--------------------+----------------------+--------------------+------------------+-------------+---------------------+------------+------------+--------------+-------------------+---------------------+---------------------------------+-----------------+------------------------+--------+---------+---------------+-----------------+------------+---+---+---+\n",
      "|Summons Number|Plate ID|Registration State|Plate Type|Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Issuing Agency|Street Code1|Street Code2|Street Code3|Vehicle Expiration Date|Violation Location|Violation Precinct|Issuer Precinct|Issuer Code|Issuer Command|Issuer Squad|Violation Time|Time First Observed|Violation County|Violation In Front Of Or Opposite|House Number|        Street Name|Intersecting Street|Date First Observed|Law Section|Sub Division|Violation Legal Code|Days Parking In Effect|From Hours In Effect|To Hours In Effect|Vehicle Color|Unregistered Vehicle?|Vehicle Year|Meter Number|Feet From Curb|Violation Post Code|Violation Description|No Standing or Stopping Violation|Hydrant Violation|Double Parking Violation|Latitude|Longitude|Community Board|Community Council|Census Tract|BIN|BBL|NTA|\n",
      "+--------------+--------+------------------+----------+----------+--------------+-----------------+------------+--------------+------------+------------+------------+-----------------------+------------------+------------------+---------------+-----------+--------------+------------+--------------+-------------------+----------------+---------------------------------+------------+-------------------+-------------------+-------------------+-----------+------------+--------------------+----------------------+--------------------+------------------+-------------+---------------------+------------+------------+--------------+-------------------+---------------------+---------------------------------+-----------------+------------------------+--------+---------+---------------+-----------------+------------+---+---+---+\n",
      "|    1298916276|  T12BRS|                NJ|       PAS|07/19/2013|            38|              SDN|       MITSU|             X|       93250|       54650|       21130|                      0|              0084|                84|            110|     330002|          T110|        0000|         0955A|                   |               K|                                F|          76|      WILLOUGHBY ST|                   |                  0|        408|          I4|                    |                  null|               0900A|             0700P|          GRY|                 null|           0|           -|             0|                   |                     |                                 |                 |                        |        |         |               |             null|            |   |   |   |\n",
      "|    1298916306|  XM867U|                NJ|       PAS|07/22/2013|            13|             DELV|       WHITE|             T|           0|           0|           0|                      0|              0084|                84|            110|     330002|          T110|        0000|         0741A|                   |               K|                                 |            |ES GALATIN ST 100FT|      S/O FULTON ST|                  0|        408|          E9|                    |                  null|                 ALL|               ALL|        WHITE|                 null|           0|           -|             0|                   |                     |                                 |                 |                        |        |         |               |             null|            |   |   |   |\n",
      "|    1298916320| 36265TR|                NY|       TRC|07/22/2013|            14|              TRC|       KENWO|             T|       77730|       42730|       56530|               20140630|              0084|                84|            110|     330002|          T110|        0000|         0815A|                   |               K|                                O|           1|           SMITH ST|                   |                  0|        408|           C|                    |                  null|                 ALL|               ALL|        WHITE|                 null|        2007|           -|             0|                   |                     |                                 |                 |                        |        |         |               |             null|            |   |   |   |\n",
      "|    1298916343| 42308JZ|                NY|       COM|07/22/2013|            14|              VAN|       CHEVR|             T|           0|           0|           0|                      0|              0084|                84|            110|     330002|          T110|        0000|         0834A|                   |               K|                                 |            |W/S BRIDGE ST 100FT|     N/O WARREN AVE|                  0|        408|           C|                    |                  null|                 ALL|               ALL|        WHITE|                 null|        2009|           -|             0|                   |                     |                                 |                 |                        |        |         |               |             null|            |   |   |   |\n",
      "|    1298916380|  96SA6S|                NY|       MOT|07/22/2013|            17|              MOT|       YAMAH|             T|       56530|       29830|       20110|               20140430|              0084|                84|            110|     330002|          T110|        0000|         0846A|                   |               K|                                O|         110|      LIVINGSTON ST|                   |                  0|        408|          C4|                    |                  null|               0700A|             0700P|          RED|                 null|           0|           -|             0|                   |                     |                                 |                 |                        |        |         |               |             null|            |   |   |   |\n",
      "|    1298916410| 69335JY|                NY|       COM|07/22/2013|            46|              VAN|       ISUZU|             T|       29830|       18950|       53830|               20140430|              0084|                84|            110|     330002|          T110|        0000|         0900A|                   |               K|                                F|          44|           COURT ST|                   |                  0|        408|          F1|                    |                  null|                 ALL|               ALL|           BL|                 null|        2007|           -|             0|                   |                     |                                 |                 |                        |        |         |               |             null|            |   |   |   |\n",
      "|    1298916422| 42092JM|                NY|       COM|07/22/2013|            74|             UTIL|       FR/LI|             T|       29830|       18950|       53830|                      0|              0084|                84|            110|     330002|          T110|        0000|         0902A|                   |               K|                                O|          44|           COURT ST|                   |                  0|        408|          E2|                    |                  null|                 ALL|               ALL|          WHT|                 null|        1999|           -|             0|                   |                     |                                 |                 |                        |        |         |               |             null|            |   |   |   |\n",
      "|    1298916434| 57944MD|                NY|       COM|07/22/2013|            46|             DELV|        FORD|             T|       29830|       42730|       73220|               20140630|              0084|                84|            110|     330002|          T110|        0000|         0905A|                   |               K|                                F|          26|           COURT ST|                   |                  0|        408|          J3|                    |                  null|                 ALL|               ALL|          WHT|                 null|        1997|           -|             0|                   |                     |                                 |                 |                        |        |         |               |             null|            |   |   |   |\n",
      "|    1298916458| 52751MA|                NY|       COM|07/22/2013|            14|              VAN|       ISUZU|             T|       27530|       75530|       81330|               20141031|              0084|                84|            110|     330002|          T110|        0000|         0913A|                   |               K|                                O|         166|         CLINTON ST|                   |                  0|        408|           C|                    |                  null|                 ALL|               ALL|        WHITE|                 null|        2005|           -|             0|                   |                     |                                 |                 |                        |        |         |               |             null|            |   |   |   |\n",
      "|    1298916495| 97707JS|                NY|       COM|07/23/2013|            14|             DELV|        MACK|             T|       52930|       63030|       93250|               20131231|              0084|                84|            110|     330002|          T110|        0000|         0644A|                   |               K|                                F|         340|             JAY ST|                   |                  0|        408|           C|                    |                  null|                 ALL|               ALL|          RED|                 null|        2005|           -|             0|                   |                     |                                 |                 |                        |        |         |               |             null|            |   |   |   |\n",
      "|    1298916501| 42308JZ|                NY|       COM|07/23/2013|            14|              VAN|       CHEVR|             T|           0|           0|           0|                      0|              0084|                84|            110|     330002|          J110|        0000|         0649A|                   |               K|                                 |            |W/S BRIDGE ST 200FT|      S/O WILLOW ST|                  0|        408|           C|                    |                  null|                 ALL|               ALL|        WHITE|                 null|        2009|           -|             0|                   |                     |                                 |                 |                        |        |         |               |             null|            |   |   |   |\n",
      "|    1298916525| 94665MC|                NY|       COM|07/23/2013|            10|             DELV|       WORKH|             T|           0|           0|           0|               20141031|              0084|                84|            110|     330002|          T110|        0000|         0703A|                   |               K|                                 |            |  S/S HOYT ST 200FT|  W/O SCHERMHORN ST|                  0|        408|           B|                    |                  null|                 ALL|               ALL|        WHITE|                 null|        2012|           -|             0|                   |                     |                                 |                 |                        |        |         |               |             null|            |   |   |   |\n",
      "|    1298916550| 7638SPC|                NY|       999|07/23/2015|            14|             DELV|       INTER|             T|           0|           0|           0|                      0|              0084|                84|            110|     330002|          T110|        0000|         0735A|                   |               K|                                 |            |W/S BRIDGE ST 200FT|      N/O WAGUGH AV|                  0|        408|           C|                    |                  null|                 ALL|               ALL|           YW|                 null|        2012|           -|             0|                   |                     |                                 |                 |                        |        |         |               |             null|            |   |   |   |\n",
      "|    1298916586| 97940JZ|                NY|       COM|07/23/2013|            46|             DELV|       WORKH|             T|       75530|       77730|       51030|                      0|              0084|                84|            110|     330002|          T110|        0000|         0756A|                   |               K|                                O|         189|       SCHERMERHORN|                   |                  0|        408|          I4|                    |                  null|                 ALL|               ALL|           BR|                 null|        2009|           -|             0|                   |                     |                                 |                 |                        |        |         |               |             null|            |   |   |   |\n",
      "|    1298916616| GFT6203|                NY|       PAS|07/23/2013|            17|             SUBN|       NISSA|             T|       56530|       29830|       20110|               20150401|              0084|                84|            110|     330002|          T110|        0000|         0807A|                   |               K|                                F|          85|      LIVINGSTON ST|                   |                  0|        408|          C4|                    |                  null|               0800A|             0600P|           BL|                 null|        2005|           -|             0|                   |                     |                                 |                 |                        |        |         |               |             null|            |   |   |   |\n",
      "|    1298916628| PAL7145|                MN|       PAS|07/23/2013|            46|             DELV|       INTLI|             T|       29830|       53830|       56530|                      0|              0084|                84|            110|     330002|          T110|        0000|         0810A|                   |               K|                                O|          65|           COURT ST|                   |                  0|        408|          F1|                    |                  null|                 ALL|               ALL|          WHT|                 null|           0|           -|             0|                   |                     |                                 |                 |                        |        |         |               |             null|            |   |   |   |\n",
      "|    1298916630| GBJ1659|                NY|       PAS|07/23/2013|            46|             SUBN|       CHEVR|             T|       20110|       40404|       40404|               20140905|              0084|                84|            110|     330002|          T110|        0000|         0813A|                   |               K|                                F|          56|           COURT SQ|                   |                  0|        408|           D|                    |                  null|                 ALL|               ALL|           BK|                 null|        2003|           -|             0|                   |                     |                                 |                 |                        |        |         |               |             null|            |   |   |   |\n",
      "|    1298916641|  9348AR|                NH|       PAS|07/23/2013|            46|             DELV|       WHITE|             T|       29830|       18950|       53830|                      0|              0084|                84|            110|     330002|          J110|        0000|         0815A|                   |               K|                                 |          44|           COURT ST|                   |                  0|        408|          F1|                    |                  null|                 ALL|               ALL|          WHT|                 null|           0|           -|             0|                   |                     |                                 |                 |                        |        |         |               |             null|            |   |   |   |\n",
      "|    1298916653| 65138JV|                NY|       COM|07/23/2013|            46|              VAN|        FORD|             T|           0|           0|           0|               20140731|              0084|                84|            110|     330002|          T110|        0000|         0819A|                   |               K|                                 |            | W/S COURT ST 40 AT|        S/O HORNELL|                  0|        408|          F1|                    |                  null|                 ALL|               ALL|          WHT|                 null|        2006|           -|             0|                   |                     |                                 |                 |                        |        |         |               |             null|            |   |   |   |\n",
      "|    1298916690| 42308JZ|                NY|       COM|07/24/2013|            14|              VAN|       CHEVR|             T|           0|           0|           0|                      0|              0084|                84|            110|     330002|          T110|        0000|         0645A|                   |               K|                                 |            |  W/S BRIDGE ST 200|     N/O W RUGBY RD|                  0|        408|           C|                    |                  null|                 ALL|               ALL|          WHT|                 null|        2009|           -|             0|                   |                     |                                 |                 |                        |        |         |               |             null|            |   |   |   |\n",
      "+--------------+--------+------------------+----------+----------+--------------+-----------------+------------+--------------+------------+------------+------------+-----------------------+------------------+------------------+---------------+-----------+--------------+------------+--------------+-------------------+----------------+---------------------------------+------------+-------------------+-------------------+-------------------+-----------+------------+--------------------+----------------------+--------------------+------------------+-------------+---------------------+------------+------------+--------------+-------------------+---------------------+---------------------------------+-----------------+------------------------+--------+---------+---------------+-----------------+------------+---+---+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "field Summons Number: LongType can not accept object '1298916276' in type <class 'str'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-9640abc08e4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m#                 df.to_csv(\"san.csv\",index=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m#                 print(df.head(2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mspark_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema_pv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m#             print(df.toPandas().head())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36mcreateDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_pandas\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0;31m# Create a DataFrame from pandas DataFrame.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m             return super(SparkSession, self).createDataFrame(\n\u001b[0m\u001b[1;32m    674\u001b[0m                 data, schema, samplingRatio, verifySchema)\n\u001b[1;32m    675\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverifySchema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/pandas/conversion.py\u001b[0m in \u001b[0;36mcreateDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    298\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_from_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimezone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverifySchema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_from_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimezone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_create_dataframe\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromLocal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m         \u001b[0mjrdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerDeUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoJavaArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_java_object_rdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplySchemaToPythonRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_createFromLocal\u001b[0;34m(self, data, schema)\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;31m# make sure data could consumed multiple times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                 \u001b[0mverify_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/types.py\u001b[0m in \u001b[0;36mverify\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1407\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mverify_nullability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m             \u001b[0mverify_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/types.py\u001b[0m in \u001b[0;36mverify_struct\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1388\u001b[0m                                 \"length of fields (%d)\" % (len(obj), len(verifiers))))\n\u001b[1;32m   1389\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverifier\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverifiers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m                     \u001b[0mverifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__dict__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m                 \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/types.py\u001b[0m in \u001b[0;36mverify\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1407\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mverify_nullability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m             \u001b[0mverify_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/types.py\u001b[0m in \u001b[0;36mverify_long\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mverify_long\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m             \u001b[0massert_acceptable_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1339\u001b[0;31m             \u001b[0mverify_acceptable_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1340\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m9223372036854775808\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m9223372036854775807\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m                 raise ValueError(\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/types.py\u001b[0m in \u001b[0;36mverify_acceptable_types\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0;31m# subclass of them can not be fromInternal in JVM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_acceptable_types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m             raise TypeError(new_msg(\"%s can not accept object %r in type %s\"\n\u001b[0m\u001b[1;32m   1292\u001b[0m                                     % (dataType, obj, type(obj))))\n\u001b[1;32m   1293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: field Summons Number: LongType can not accept object '1298916276' in type <class 'str'>"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import from_json\n",
    "\n",
    "#use model to transform\n",
    "pm = PipelineModel.load(\"../pretrained_models/va_model\")\n",
    "# use pre trained model to infer\n",
    "pred_model = PipelineModel.load(\"../pretrained_models/rf_model\")\n",
    "\n",
    "# Count rows every 1 seconds while stream is active\n",
    "try:\n",
    "    i=1\n",
    "    # While stream is active, print count\n",
    "    while len(spark.streams.active) > 0:        \n",
    "        # Clear output\n",
    "        clear_output(wait=True)\n",
    "        print(\"Run:{}\".format(i))\n",
    "        lst_queries=[]\n",
    "        for s in spark.streams.active:\n",
    "            lst_queries.append(s.name)\n",
    "            \n",
    "        if \"ny_pv_count\" in lst_queries:\n",
    "            # Count number of events            \n",
    "            df = spark.sql(\"select * from ny_pv_count\")\n",
    "            print('Calling preprocess_data')\n",
    "            vec_df = preprocess_data(spark_df,pm)\n",
    "            print('Calling predict_data')\n",
    "            pr = predict_data(vec_df,pred_model).toPandas()\n",
    "            print(pr['Violation_Location'])\n",
    "        sleep(1)\n",
    "        i=i+1\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    queryMem.stop()    \n",
    "    print(\"stream process interrupted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%connect_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
